from google.cloud import bigquery
import os

class BigQuery:
    def __init__(self, dataset_id):
        self.project_id = os.getenv("PROJECT_ID")  # í™˜ê²½ë³€ìˆ˜ ìš°ì„ , fallbackìœ¼ë¡œ ì¸ì ì‚¬ìš©
        self.dataset_id = dataset_id
        self.client = bigquery.Client(project=self.project_id)

    def create_dataset(self, location="asia-northeast3", description=""):
        """ë°ì´í„°ì…‹ ìƒì„±"""
        dataset_ref = f"{self.project_id}.{self.dataset_id}"
        dataset = bigquery.Dataset(dataset_ref)
        dataset.location = location
        dataset.description = description

        dataset = self.client.create_dataset(dataset, exists_ok=True)
        print(f"ğŸ“ ë°ì´í„°ì…‹ ìƒì„±ë¨: {dataset.dataset_id} ({location})")

    def run_query(self, query):
        """SQL ì¿¼ë¦¬ ì‹¤í–‰ í›„ DataFrame ë°˜í™˜"""
        query_job = self.client.query(query)
        result = query_job.result()
        return result.to_dataframe()

    def upload_dataframe(self, df, table_name, overwrite=False):
        """DataFrameì„ í…Œì´ë¸”ë¡œ ì—…ë¡œë“œ"""
        table_id = f"{self.project_id}.{self.dataset_id}.{table_name}"
        job_config = bigquery.LoadJobConfig(
            write_disposition="WRITE_APPEND",  # ê¸°ì¡´ì— ê°™ì€ íŒŒí‹°ì…˜ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸° í•˜ë ¤ë©´ MERGE í•„ìš”
            time_partitioning=bigquery.TimePartitioning(
                type_=bigquery.TimePartitioningType.DAY,
                field="event_date",
            ),
        )
        job = self.client.load_table_from_dataframe(df, table_id, job_config=job_config)
        job.result()  # ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {table_id}")

    def get_table_schema(self, table_name):
        """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸"""
        table_id = f"{self.project_id}.{self.dataset_id}.{table_name}"
        table = self.client.get_table(table_id)
        return table.schema
